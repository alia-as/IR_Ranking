{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhHXrYp3DShI",
        "outputId": "e6499e8f-3557-4e69-f1c8-cba2ffc04661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from collections import defaultdict\n",
        "from typing import Union, Callable, Iterable, Literal\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/School/IR/Fourth/cranfield-trec-dataset-main'\n",
        "docs = pd.read_xml(path + '/cran.all.1400.xml')[['title', 'text', 'docno']].set_index('docno')\n",
        "queries = pd.read_xml(path + '/cran.qry.xml').set_index('num')\n",
        "relevance = pd.read_csv(path + '/cranqrel.trec.txt', sep=' ', usecols=['topic', 'doc', 'rel'])\n",
        "print(docs.head())\n",
        "print(queries.head())\n",
        "print(relevance.head())"
      ],
      "metadata": {
        "id": "C9-hCgnOFZ7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffe4253-5e4e-4fe9-9dac-2b8e4c5f8861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   title  \\\n",
            "docno                                                      \n",
            "1      experimental investigation of the aerodynamics...   \n",
            "2      simple shear flow past a flat plate in an inco...   \n",
            "3      the boundary layer in simple shear flow past a...   \n",
            "4      approximate solutions of the incompressible la...   \n",
            "5      one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                    text  \n",
            "docno                                                     \n",
            "1      experimental investigation of the aerodynamics...  \n",
            "2      simple shear flow past a flat plate in an inco...  \n",
            "3      the boundary layer in simple shear flow past a...  \n",
            "4      approximate solutions of the incompressible la...  \n",
            "5      one-dimensional transient heat conduction into...  \n",
            "                                                 title\n",
            "num                                                   \n",
            "1    what similarity laws must be obeyed when const...\n",
            "2    what are the structural and aeroelastic proble...\n",
            "4    what problems of heat conduction in composite ...\n",
            "8    can a criterion be developed to show empirical...\n",
            "9    what chemical kinetic system is applicable to ...\n",
            "   topic  doc  rel\n",
            "0      1  184    1\n",
            "1      1   29    1\n",
            "2      1   31    1\n",
            "3      1   12    1\n",
            "4      1   51    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and lemmatizing words\n",
        "\n",
        "def preprocess(Doc:str, tokenizer:Callable=None, stop_words:Iterable=None, lemmatizer:Callable=None, verbose:int=0) -> list[list[str]]:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    ---\n",
        "    `Doc`: the document\n",
        "\n",
        "    `tokenizer`: The tokenizing function for tokenizing the documents\n",
        "\n",
        "    `stop_words`: The list of stop words to be removed from tokens\n",
        "\n",
        "    `lemmatizer`: A function to lemmatize the tokens\n",
        "\n",
        "    Returns:\n",
        "    ---\n",
        "    The tokens list!\n",
        "    \"\"\"\n",
        "    Marks = {\".\", \",\", \"?\", \"!\"}\n",
        "    if tokenizer == None:\n",
        "      tokenizer = word_tokenize\n",
        "    if lemmatizer == None:\n",
        "      lemmatizer = WordNetLemmatizer().lemmatize\n",
        "    if stop_words == None:\n",
        "      stop_words = set(stopwords.words('english')).difference({'not'}).union(Marks)\n",
        "    def get_wordnet_pos(treebank_tag):\n",
        "        if treebank_tag.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif treebank_tag.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif treebank_tag.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif treebank_tag.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        else:\n",
        "            return wordnet.NOUN  # for punctuation marks\n",
        "\n",
        "    for i in range(len(Doc)):\n",
        "      if Doc[i] in Marks:\n",
        "        if Doc[i] in {'.', ','} and (Doc[i-1].isnumeric() or i == 0) and (Doc[i+1].isnumeric() or i == len(Doc) - 1):\n",
        "          continue # In this case, marks are thousand seperator or decimal point\n",
        "        # putting space after marks when needed\n",
        "        Doc = Doc[:i + 1] + \" \" + Doc[i + 1:]\n",
        "    Words = [w for w in tokenizer(Doc) if w not in stop_words]\n",
        "\n",
        "    if verbose > 0:\n",
        "        for w in Words:\n",
        "            print(w)\n",
        "\n",
        "    if lemmatizer:\n",
        "          tags = nltk.pos_tag(Words)\n",
        "          for j in range(len(Words)):\n",
        "              Words[j] = lemmatizer(Words[j], pos=get_wordnet_pos(tags[j][1]))\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(\"-\"*50)\n",
        "        for w in Words:\n",
        "            print(w)\n",
        "\n",
        "    return Words"
      ],
      "metadata": {
        "id": "Y1My7ke7IMKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save each term in a dict (I didnt use TRIE anymore in new versions as it isn't efficient in Python),\n",
        "# `termDict` keys are terms. Value is a dict, where keys are docnoms, values are their positions\n",
        "# tf: len(termDict[term][docno])/len(docs_tokens[docno]), df: len(termDict[term])\n",
        "termDict = defaultdict(lambda: defaultdict(lambda: []))\n",
        "docs_tokens = []\n",
        "for docno in docs.index:\n",
        "  doc = docs.loc[docno]\n",
        "  # print(doc['text'])\n",
        "  print(end=f\"\\r{docno}\")\n",
        "  if doc['text']:\n",
        "    text  = preprocess(doc['text'])\n",
        "    docs_tokens.append(text)\n",
        "    for i in range(len(text)):\n",
        "      term = text[i]\n",
        "      termDict[term][docno].append(i)"
      ],
      "metadata": {
        "id": "QczCgvXNWadY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba421e9-e7b1-4c5c-c417-1427a5f64322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(termDict.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5qsMNn0y_gi",
        "outputId": "84d8a91c-f50a-47a9-d001-da0da04dcd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF based Ranking"
      ],
      "metadata": {
        "id": "E1eo9z1a1ooL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_tfidf(query_tokens:list[str], term_dict:dict[str, dict[int, list[int]]], docs_tokens:list[list[str]], verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  def termFreq(term:str, doc_tokens:list[str]) -> float:\n",
        "    return doc_tokens.count(term)/len(doc_tokens)\n",
        "  def cal_tfidf(term:str, doc_tokens:list[str], tf_mode='n'):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----\n",
        "    `term`: term\n",
        "    `doc_tokens`: The tokens in the document\n",
        "    `tf_mode`: Term freq weight  'n' for natural, 'l': logarithm, 'a': augmented, 'b': boolean, `L`: log avg\n",
        "    \"\"\"\n",
        "    if term not in doc_tokens:\n",
        "      return 0\n",
        "    tf = termFreq(term, doc_tokens)\n",
        "    df = len(term_dict[term])\n",
        "    idf = 1 + np.log(N / df)\n",
        "    if tf_mode == 'l':\n",
        "      tf = 1 + np.log(tf)\n",
        "    elif tf_mode == 'a':\n",
        "      tf = 0.5 + (0.5 + tf) / max([termFreq(t, doc_tokens) for t in doc_tokens])\n",
        "    elif tf_mode == 'b':\n",
        "      tf = tf > 0\n",
        "    elif tf_mode == 'L':\n",
        "      tf = (1 + np.log(tf)) / (1 + np.log(np.mean([termFreq(t, doc_tokens) for t in doc_tokens])))\n",
        "\n",
        "    if verbose > 1:\n",
        "      print(f\"For term {term}: tf = {tf}, and idf = {idf}\")\n",
        "    return tf * idf\n",
        "\n",
        "  query_tokens_set = set(query_tokens)\n",
        "  qVec = np.array([cal_tfidf(t, query_tokens) for t in query_tokens_set])\n",
        "  qVecNorm = np.linalg.norm(qVec)\n",
        "  if verbose > 0:\n",
        "    print(f\"query vector: {qVec}\")\n",
        "  scores = []\n",
        "  for i in range(N):\n",
        "    docVec = np.array([cal_tfidf(t, docs_tokens[i]) for t in query_tokens_set])\n",
        "    inner = np.inner(qVec, docVec)\n",
        "    score = 0 if inner == 0 else inner / (np.linalg.norm(docVec) * qVecNorm)\n",
        "    if verbose > 0:\n",
        "      print(f\"doc vec = {docVec}, and score is {score}\")\n",
        "    scores.append((i, score))\n",
        "\n",
        "  return sorted(scores, reverse=True, key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "rletkHv1oXoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Okapi (BM25) Ranking\n",
        "The **RSV** for each document is as below: \\\\\n",
        "$\n",
        "RSV_d = \\Sigma_{t\\in q}{[log \\frac{N}{df_t}] . \\frac{(k_1 + 1)tf_d}{k_1((1-b) + b \\times (L_d / L_{avg})) + tf_d} . \\frac{(k_3 + 1)tf_q}{k_3 + tf_q}}\n",
        "$"
      ],
      "metadata": {
        "id": "aCH8qgnSUUwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_okapi(query_tokens:list[str],\n",
        "               term_dict:dict[str, dict[int, list[int]]],\n",
        "               docs_tokens:list[list[str]],\n",
        "               b=0.75, k1=1.2, k3=2, verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  def RSV(doc:list[str]):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----\n",
        "    `doc`: list of doc's tokens\n",
        "\n",
        "    Returns:\n",
        "    -----\n",
        "    the RSV score\n",
        "    \"\"\"\n",
        "    Lavg = np.mean([len(doc) for doc in docs_tokens])\n",
        "    ans = 0\n",
        "    for term in set(doc):\n",
        "      tfd = doc.count(term)\n",
        "      tfq = query_tokens.count(term)\n",
        "      idf = np.log(N / len(term_dict[term]))\n",
        "      dweight = ((k1 + 1)*tfd) / (k1*((1-b) + b*(len(doc) / Lavg)) + tfd)\n",
        "      qweight = ((k3 + 1)*tfq) / (k3 + tfq)\n",
        "      ans += idf * dweight * qweight\n",
        "    return ans\n",
        "\n",
        "  scores = []\n",
        "  for i in range(N):\n",
        "    doc = docs_tokens[i]\n",
        "    scores.append((i, RSV(doc)))\n",
        "\n",
        "  return sorted(scores, reverse=True, key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "lwe0htCcQyIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Ranking\n",
        "Rank based on: \\\\\n",
        "> $P(q|M_d) = Π_{1\\le i \\le |q|}{P(t_i|M_d)}$ \\\\\n",
        "\n",
        "By taking $log$ we can rank based on: \\\\\n",
        "> $P(q|M_d) = \\Sigma_{1\\le i \\le |q|}{log(P(t_i|M_d))}$ \\\\\n",
        "\n",
        "Where\n",
        " $P(t_i|M_d) = \\frac{tf_{t_i, d}}{L_d}$\n",
        "\n",
        " ----\n",
        " ## 2 Smoothing Method\n",
        " > ## Jelinek-Mercer\n",
        "\n",
        " $\\quad P = λ * P(t|M_d) + (1-λ) * P(t|M_c)$\n",
        "\n",
        " > ## Dirichlet\n",
        "\n",
        " $\\quad P = \\frac{tf_{t,d} + α P(t|M_c)}{L_d + α}$"
      ],
      "metadata": {
        "id": "QuAWGBZxnnUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_langModel(query_tokens:list[str],\n",
        "               term_dict:dict[str, dict[int, list[int]]],\n",
        "               docs_tokens:list[list[str]],\n",
        "               smoothing:Literal['jelinek', 'dirichlet']='jelinek',\n",
        "               lambdaa:float=0.5, alpha:float=0.5,\n",
        "               verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  pcols = {t:sum([len(term_dict[t][d]) for d in term_dict[t]]) / sum([len(d) for d in docs_tokens]) for t in query_tokens}\n",
        "  if verbose > 1:print(\"P(t|M_c)=\\n\" + \"\\n\".join(f\"{key}: {pcols[key]}\" for key in pcols))\n",
        "  def probQ_Doc(doc:list[str]):\n",
        "    ans = 1\n",
        "    for term in query_tokens:\n",
        "      pcol = pcols[term]\n",
        "      p = 0\n",
        "      if smoothing == 'jelinek':\n",
        "        pdoc = doc.count(term) / len(doc)\n",
        "        p = lambdaa * pdoc + (1-lambdaa) * pcol\n",
        "        if verbose > 1: print(f\"term {term}: P(t|M_d)={pdoc}\")\n",
        "      elif smoothing == 'dirichlet':\n",
        "        p = (doc.count(term) + alpha*pcol) / (len(doc) + alpha)\n",
        "        if verbose > 1: print(f\"term {term}: p = {doc.count(term) + alpha*pcol} / {len(doc) + alpha}\")\n",
        "      else:\n",
        "        raise ValueError(\"You should use some smoothing method\")\n",
        "      if verbose:print(f\"ans={ans}, p={p}\")\n",
        "      ans *= p\n",
        "    return ans\n",
        "\n",
        "  scores = []\n",
        "  for i in range(N):\n",
        "    scores.append((i, probQ_Doc(docs_tokens[i])))\n",
        "  return sorted(scores, reverse=True, key=lambda x: x[1])\n"
      ],
      "metadata": {
        "id": "Bp4IqWN6f7F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "DOXZzPcE-hph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qqqq = ['machine learning teaches machine how to learn'.split(), 'machine translation is my favorite subject'.split(), 'term frequency and inverse document frequency is important'.split()]\n",
        "wwww = defaultdict(lambda: defaultdict(lambda: []))\n",
        "for i in range(len(qqqq)):\n",
        "  d = qqqq[i]\n",
        "  for j in range(len(d)):\n",
        "    t = d[j]\n",
        "    wwww[t][i].append(j)\n",
        "print(rank_tfidf(['machine', 'learning'], wwww, qqqq, verbose=0))\n",
        "print(\"-\" * 75)\n",
        "\n",
        "print(rank_okapi(['machine', 'learning'], wwww, qqqq, verbose=0))\n",
        "print(\"-\" * 75)\n",
        "\n",
        "print(rank_langModel(['machine', 'learning'], wwww, qqqq, verbose=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmqSJh6deN-Z",
        "outputId": "b1645d0a-e617-48c6-efa7-946e22c0adb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.9429634084277353), (1, 0.5564505207186616), (2, 0)]\n",
            "---------------------------------------------------------------------------\n",
            "[(0, 1.6561268123168358), (1, 0.43063190792177464), (2, 0.0)]\n",
            "---------------------------------------------------------------------------\n",
            "[(0, 0.02040816326530612), (1, 0.0036848072562358277), (2, 0.0017006802721088433)]\n"
          ]
        }
      ]
    }
  ]
}