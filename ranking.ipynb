{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhHXrYp3DShI",
        "outputId": "c1f070fd-c977-475f-98c5-4fdfe9ef5f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from collections import defaultdict\n",
        "from typing import Union, Callable, Iterable, Literal\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/School/IR/Fourth/cranfield-trec-dataset-main'\n",
        "docs = pd.read_xml(path + '/cran.all.1400.xml')[['title', 'text', 'docno']].set_index('docno')\n",
        "queries = pd.read_xml(path + '/cran.qry.xml').set_index('num')\n",
        "relevance = pd.read_csv(path + '/cranqrel.trec.txt', sep=' ', usecols=['topic', 'doc', 'rel'])\n",
        "relevance.columns = ['query', 'doc', 'rel']\n",
        "queries.columns = ['query']\n",
        "print(docs.head())\n",
        "print(queries.head())\n",
        "print(relevance.head())"
      ],
      "metadata": {
        "id": "C9-hCgnOFZ7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f378f2-8f43-4c2b-fe7b-73cf450c82fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   title  \\\n",
            "docno                                                      \n",
            "1      experimental investigation of the aerodynamics...   \n",
            "2      simple shear flow past a flat plate in an inco...   \n",
            "3      the boundary layer in simple shear flow past a...   \n",
            "4      approximate solutions of the incompressible la...   \n",
            "5      one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                    text  \n",
            "docno                                                     \n",
            "1      experimental investigation of the aerodynamics...  \n",
            "2      simple shear flow past a flat plate in an inco...  \n",
            "3      the boundary layer in simple shear flow past a...  \n",
            "4      approximate solutions of the incompressible la...  \n",
            "5      one-dimensional transient heat conduction into...  \n",
            "                                                 query\n",
            "num                                                   \n",
            "1    what similarity laws must be obeyed when const...\n",
            "2    what are the structural and aeroelastic proble...\n",
            "4    what problems of heat conduction in composite ...\n",
            "8    can a criterion be developed to show empirical...\n",
            "9    what chemical kinetic system is applicable to ...\n",
            "   query  doc  rel\n",
            "0      1  184    1\n",
            "1      1   29    1\n",
            "2      1   31    1\n",
            "3      1   12    1\n",
            "4      1   51    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and lemmatizing words\n",
        "\n",
        "def preprocess(Doc:str, tokenizer:Callable=None, stop_words:Iterable=None, lemmatizer:Callable=None, verbose:int=0) -> list[list[str]]:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    ---\n",
        "    `Doc`: the document\n",
        "\n",
        "    `tokenizer`: The tokenizing function for tokenizing the documents\n",
        "\n",
        "    `stop_words`: The list of stop words to be removed from tokens\n",
        "\n",
        "    `lemmatizer`: A function to lemmatize the tokens\n",
        "\n",
        "    Returns:\n",
        "    ---\n",
        "    The tokens list!\n",
        "    \"\"\"\n",
        "    Marks = {\".\", \",\", \"?\", \"!\"}\n",
        "    if tokenizer == None:\n",
        "      tokenizer = word_tokenize\n",
        "    if lemmatizer == None:\n",
        "      lemmatizer = WordNetLemmatizer().lemmatize\n",
        "    if stop_words == None:\n",
        "      stop_words = set(stopwords.words('english')).difference({'not'}).union(Marks)\n",
        "    def get_wordnet_pos(treebank_tag):\n",
        "        if treebank_tag.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif treebank_tag.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif treebank_tag.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif treebank_tag.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        else:\n",
        "            return wordnet.NOUN  # for punctuation marks\n",
        "\n",
        "    for i in range(len(Doc)):\n",
        "      if Doc[i] in Marks:\n",
        "        if Doc[i] in {'.', ','} and (Doc[i-1].isnumeric() or i == 0) and (Doc[i+1].isnumeric() or i == len(Doc) - 1):\n",
        "          continue # In this case, marks are thousand seperator or decimal point\n",
        "        # putting space after marks when needed\n",
        "        Doc = Doc[:i + 1] + \" \" + Doc[i + 1:]\n",
        "    Words = [w for w in tokenizer(Doc) if w not in stop_words]\n",
        "\n",
        "    if verbose > 0:\n",
        "        for w in Words:\n",
        "            print(w)\n",
        "\n",
        "    if lemmatizer:\n",
        "          tags = nltk.pos_tag(Words)\n",
        "          for j in range(len(Words)):\n",
        "              Words[j] = lemmatizer(Words[j], pos=get_wordnet_pos(tags[j][1]))\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(\"-\"*50)\n",
        "        for w in Words:\n",
        "            print(w)\n",
        "\n",
        "    return Words"
      ],
      "metadata": {
        "id": "Y1My7ke7IMKU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save each term in a dict (I didnt use TRIE anymore in new versions as it isn't efficient in Python),\n",
        "# `termDict` keys are terms. Value is a dict, where keys are docIDs, values are their positions\n",
        "# tf: len(termDict[term][docno])/len(docs_tokens[docno]), df: len(termDict[term])\n",
        "termDict = defaultdict(lambda: defaultdict(lambda: []))\n",
        "docs_tokens = {}\n",
        "for docno in docs.index:\n",
        "  doc = docs.loc[docno]\n",
        "  # print(doc['text'])\n",
        "  print(end=f\"\\r{docno}\")\n",
        "  if doc['text']:\n",
        "    text  = preprocess(doc['text'])\n",
        "    docs_tokens[str(docno)] = text\n",
        "    for i in range(len(text)):\n",
        "      term = text[i]\n",
        "      termDict[term][str(docno)].append(i)"
      ],
      "metadata": {
        "id": "QczCgvXNWadY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8267b98e-b212-4ac0-dc36-8d02d495562b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(termDict.keys()))"
      ],
      "metadata": {
        "id": "C5qsMNn0y_gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d8fcb8-b468-44e4-f6a3-81a4d54903db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF based Ranking"
      ],
      "metadata": {
        "id": "E1eo9z1a1ooL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_tfidf(query_tokens:list[str], term_dict:dict[str, dict[str, list[int]]], docs_tokens:dict[str,list[str]], k:int=None, verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  calculate a vector for the query and each document, and rank based on\n",
        "  the similarity between the query vector and each doc vector.\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  'k': The k best will be returned\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  def termFreq(term:str, doc_tokens:list[str]) -> float:\n",
        "    return doc_tokens.count(term)/len(doc_tokens)\n",
        "  def cal_tfidf(term:str, doc_tokens:list[str], tf_mode='n'):\n",
        "    \"\"\"\n",
        "    calculate the tf-idf value for a term and a doc\n",
        "    Parameters:\n",
        "    -----\n",
        "    `term`: term\n",
        "    `doc_tokens`: The tokens in the document\n",
        "    `tf_mode`: Term freq weight  'n' for natural, 'l': logarithm, 'a': augmented, 'b': boolean, `L`: log avg\n",
        "    \"\"\"\n",
        "    if term not in doc_tokens or not term_dict[term]:\n",
        "      return 0\n",
        "    tf = termFreq(term, doc_tokens)\n",
        "    df = len(term_dict[term])\n",
        "    idf = 1 + np.log(N / df)\n",
        "    if tf_mode == 'l':\n",
        "      tf = 1 + np.log(tf)\n",
        "    elif tf_mode == 'a':\n",
        "      tf = 0.5 + (0.5 + tf) / max([termFreq(t, doc_tokens) for t in doc_tokens])\n",
        "    elif tf_mode == 'b':\n",
        "      tf = tf > 0\n",
        "    elif tf_mode == 'L':\n",
        "      tf = (1 + np.log(tf)) / (1 + np.log(np.mean([termFreq(t, doc_tokens) for t in doc_tokens])))\n",
        "\n",
        "    if verbose > 1:\n",
        "      print(f\"For term {term}: tf = {tf}, and idf = {idf}\")\n",
        "    return tf * idf\n",
        "\n",
        "  query_tokens_set = set(query_tokens)\n",
        "  qVec = np.array([cal_tfidf(t, query_tokens) for t in query_tokens_set]) # The query vector\n",
        "  qVecNorm = np.linalg.norm(qVec)\n",
        "  if verbose > 0:\n",
        "    print(f\"query vector: {qVec}\")\n",
        "  scores = []\n",
        "  for i in docs_tokens.keys():\n",
        "    docVec = np.array([cal_tfidf(t, docs_tokens[i]) for t in query_tokens_set])\n",
        "    inner = np.inner(qVec, docVec)\n",
        "    score = 0 if inner == 0 else inner / (np.linalg.norm(docVec) * qVecNorm)\n",
        "    if verbose > 0:\n",
        "      print(f\"doc vec = {docVec}, and score is {score}\")\n",
        "    scores.append({'Id': i, 'Score': score})\n",
        "\n",
        "  if k == None:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])\n",
        "  else:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])[:k]"
      ],
      "metadata": {
        "id": "rletkHv1oXoQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Okapi (BM25) Ranking\n",
        "The **RSV** for each document is as below: \\\\\n",
        "$\n",
        "RSV_d = \\Sigma_{t\\in q}{[log \\frac{N}{df_t}] . \\frac{(k_1 + 1)tf_d}{k_1((1-b) + b \\times (L_d / L_{avg})) + tf_d} . \\frac{(k_3 + 1)tf_q}{k_3 + tf_q}}\n",
        "$"
      ],
      "metadata": {
        "id": "aCH8qgnSUUwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_okapi(query_tokens:list[str],\n",
        "               term_dict:dict[str, dict[str, list[int]]],\n",
        "               docs_tokens:dict[str,list[str]],\n",
        "               b=0.75, k1=1.2, k3=2, k:int=None, verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  'k': The k best will be returned\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  def RSV(doc:list[str]):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----\n",
        "    `doc`: list of doc's tokens\n",
        "\n",
        "    Returns:\n",
        "    -----\n",
        "    the RSV score\n",
        "    \"\"\"\n",
        "    Lavg = np.mean([len(docs_tokens[docID]) for docID in docs_tokens.keys()])\n",
        "    ans = 0\n",
        "    for term in set(doc):\n",
        "      tfd = doc.count(term)\n",
        "      tfq = query_tokens.count(term)\n",
        "      idf = np.log(N / len(term_dict[term]))\n",
        "      dweight = ((k1 + 1)*tfd) / (k1*((1-b) + b*(len(doc) / Lavg)) + tfd)\n",
        "      qweight = ((k3 + 1)*tfq) / (k3 + tfq)\n",
        "      ans += idf * dweight * qweight\n",
        "    return ans\n",
        "\n",
        "  scores = []\n",
        "  for i in docs_tokens.keys():\n",
        "    doc = docs_tokens[i]\n",
        "    scores.append({'Id': i, 'Score': RSV(doc)})\n",
        "\n",
        "  if k == None:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])\n",
        "  else:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])[:k]"
      ],
      "metadata": {
        "id": "lwe0htCcQyIX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Ranking\n",
        "Rank based on: \\\\\n",
        "> $P(q|M_d) = Π_{1\\le i \\le |q|}{P(t_i|M_d)}$ \\\\\n",
        "\n",
        "By taking $log$ we can rank based on: \\\\\n",
        "> $P(q|M_d) = \\Sigma_{1\\le i \\le |q|}{log(P(t_i|M_d))}$ \\\\\n",
        "\n",
        "Where\n",
        " $P(t_i|M_d) = \\frac{tf_{t_i, d}}{L_d}$\n",
        "\n",
        " ----\n",
        " ## 2 Smoothing Method\n",
        " > ## Jelinek-Mercer\n",
        "\n",
        " $\\quad P = λ * P(t|M_d) + (1-λ) * P(t|M_c)$\n",
        "\n",
        " > ## Dirichlet\n",
        "\n",
        " $\\quad P = \\frac{tf_{t,d} + α P(t|M_c)}{L_d + α}$"
      ],
      "metadata": {
        "id": "QuAWGBZxnnUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_langModel(query_tokens:list[str],\n",
        "               term_dict:dict[str, dict[int, list[int]]],\n",
        "               docs_tokens:dict[str,list[str]],\n",
        "               smoothing:Literal['jelinek', 'dirichlet']='jelinek',\n",
        "               lambdaa:float=0.5, alpha:float=0.5, k:int=None,\n",
        "               verbose:int=0) -> list[int]:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  -----\n",
        "  `query`: The query tokens!\n",
        "  `term_dict`: The dictionary of terms as described above\n",
        "  `docs_tokens`: The tokens of each document\n",
        "  'k': The k best will be returned\n",
        "  `verbose`: Verbosity\n",
        "\n",
        "  Returns:\n",
        "  -----\n",
        "  sorted indices of docs (based on `docs_tokens`)\n",
        "  \"\"\"\n",
        "  N = len(docs_tokens)\n",
        "  pcols = {t:sum([len(term_dict[t][docID]) for docID in term_dict[t].keys()]) / sum([len(docs_tokens[docID]) for docID in docs_tokens.keys()]) for t in query_tokens}\n",
        "  if verbose > 1:print(\"P(t|M_c)=\\n\" + \"\\n\".join(f\"{key}: {pcols[key]}\" for key in pcols))\n",
        "  def probQ_Doc(doc:list[str]):\n",
        "    ans = 1\n",
        "    for term in query_tokens:\n",
        "      pcol = pcols[term]\n",
        "      p = 0\n",
        "      if smoothing == 'jelinek':\n",
        "        pdoc = doc.count(term) / len(doc)\n",
        "        p = lambdaa * pdoc + (1-lambdaa) * pcol\n",
        "        if verbose > 1: print(f\"term {term}: P(t|M_d)={pdoc}\")\n",
        "      elif smoothing == 'dirichlet':\n",
        "        p = (doc.count(term) + alpha*pcol) / (len(doc) + alpha)\n",
        "        if verbose > 1: print(f\"term {term}: p = {doc.count(term) + alpha*pcol} / {len(doc) + alpha}\")\n",
        "      else:\n",
        "        raise ValueError(\"You should use some smoothing method\")\n",
        "      if verbose:print(f\"ans={ans}, p={p}\")\n",
        "      ans *= p\n",
        "    return ans\n",
        "\n",
        "  scores = []\n",
        "  for i in docs_tokens.keys():\n",
        "    scores.append({'Id': i, 'Score': probQ_Doc(docs_tokens[i])})\n",
        "  if k == None:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])\n",
        "  else:\n",
        "    return sorted(scores, reverse=True, key=lambda x: x['Score'])[:k]"
      ],
      "metadata": {
        "id": "Bp4IqWN6f7F6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # Comparing Methods\n",
        "\n",
        "## Unknown Queries!\n",
        "There are 73 queries (from `226` to `365`) without any relevant document in the dataset! So, for comparison reasons, we should ignore these queries.\n",
        "\n",
        "## 11-point interpolated average precision\n",
        "To compare these 3 methods, we use this plot for a few queries (and also for average of all of them)."
      ],
      "metadata": {
        "id": "7cXpP4prW3IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_point_interpolated_avg_prec(ranked_result, relevants, k:int=11, draw:bool=False):\n",
        "  points = pd.DataFrame([{'recall': i/(k-1), 'precision': -1} for i in range(k)])\n",
        "  rel_founded = 0\n",
        "  points_index = 0\n",
        "  i1 = -1\n",
        "  while rel_founded == 0:\n",
        "    i1 += 1\n",
        "    if int(ranked_result[i1]['Id']) in relevants:\n",
        "      rel_founded = 1\n",
        "      points.loc[points_index, 'precision'] = 1 / (i1+1)\n",
        "      points_index = 1\n",
        "      break\n",
        "\n",
        "  for i in range(i1+1, len(ranked_result)):\n",
        "    if int(ranked_result[i]['Id']) in relevants:\n",
        "      rel_founded += 1\n",
        "    while points_index < points.shape[0] and points.loc[points_index, 'recall'] <= rel_founded / len(relevants):\n",
        "      points.loc[points_index, 'precision'] = rel_founded / (i+1)\n",
        "      points_index += 1\n",
        "    if rel_founded >= len(relevants):break\n",
        "  if draw:\n",
        "    plt.plot(points['recall'], points['precision'])\n",
        "  return points\n"
      ],
      "metadata": {
        "id": "iAKi2bZyYmSV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_points = pd.DataFrame({'method': ['tfidf'] * 11 + ['okapi'] * 11 + ['langModel'] * 11,\n",
        "                           'recall': [i/10 for i in range(11)] * 3, 'precision': np.zeros(33, dtype=np.float64)})\n",
        "queryCount = len(queries)\n",
        "nullQueries = 0 # Number of queries without any relevant doc\n",
        "for qnum in queries.index[:queryCount]:\n",
        "  if 226 <= qnum and qnum <= 365:\n",
        "    nullQueries += 1\n",
        "    continue\n",
        "  print(end=f'\\r{qnum}')\n",
        "  relevants = relevance[(relevance['query'] == qnum) & relevance['rel'] == 1]['doc'].values\n",
        "  query_tokens = preprocess(queries.loc[qnum]['query'])\n",
        "\n",
        "  result_tfidf = rank_tfidf(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "  result_okapi = rank_okapi(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "  result_langModel = rank_langModel(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "\n",
        "  points_tfidf = k_point_interpolated_avg_prec(result_tfidf, relevants)\n",
        "  points_okapi = k_point_interpolated_avg_prec(result_okapi, relevants)\n",
        "  points_langModel = k_point_interpolated_avg_prec(result_langModel, relevants)\n",
        "\n",
        "  avg_points.loc[avg_points['method'] == 'okapi', 'precision'] += points_okapi['precision'].values\n",
        "  avg_points.loc[avg_points['method'] == 'tfidf', 'precision'] += points_tfidf['precision'].values\n",
        "  avg_points.loc[avg_points['method'] == 'langModel', 'precision'] += points_langModel['precision'].values\n",
        "\n",
        "\n",
        "\n",
        "avg_points.loc[:, 'precision'] /= (queryCount - nullQueries)\n",
        "fig = px.line(avg_points, x=\"recall\", y=\"precision\", color='method')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "3dbjWB1Dgqta",
        "outputId": "e8cf0ec1-cd8d-4ee3-b3c7-2f94487e87b4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"77266591-8110-444d-8607-48017ef72a8b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"77266591-8110-444d-8607-48017ef72a8b\")) {                    Plotly.newPlot(                        \"77266591-8110-444d-8607-48017ef72a8b\",                        [{\"hovertemplate\":\"method=tfidf\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"tfidf\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"tfidf\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.025525587266506347,0.020009880261797588,0.01781009478394741,0.013251186809586826,0.011793195604199879,0.011111937456267559,0.009578285382433075,0.008579972457328958,0.008071153944614549,0.007788420851268014,0.007312315656345366],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"method=okapi\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"okapi\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"okapi\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.028921964353238145,0.026772986402720557,0.01756279661175702,0.014217374588839616,0.01363150861651377,0.013151329906535314,0.011558050191315757,0.00979270537708081,0.008913501395217262,0.00852730261818219,0.007821622327634564],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"method=langModel\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"langModel\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"langModel\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.027268672546743297,0.025187546315093217,0.018078344247131055,0.01278112452171667,0.012062140850207265,0.011283414700515226,0.010360557502698207,0.008903004957340557,0.008501029697059426,0.008127504176105723,0.007566086312585412],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"recall\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"precision\"}},\"legend\":{\"title\":{\"text\":\"method\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('77266591-8110-444d-8607-48017ef72a8b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the above plot, `Okapi` (`BM25`) was almost the best one in this experiment. And after that, the `Language Model` was the next.\n",
        "\n",
        "`TF-IDF` was the earliest and simplest method and predictably, it was the worst one, except for recall $0.2$ and $0.3$."
      ],
      "metadata": {
        "id": "ZWfzOw5j_cRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot a query\n",
        "> Use the function below to plot 11-point interpolated average precision for each of the 3 methods"
      ],
      "metadata": {
        "id": "rpvjxhqx-6An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotQuery(qnum):\n",
        "  points = pd.DataFrame({'method': ['tfidf'] * 11 + ['okapi'] * 11 + ['langModel'] * 11,\n",
        "                        'recall': [i/10 for i in range(11)] * 3, 'precision': np.zeros(33, dtype=np.float64)})\n",
        "\n",
        "  relevants = relevance[(relevance['query'] == qnum) & relevance['rel'] == 1]['doc'].values\n",
        "  query_tokens = preprocess(queries.loc[qnum]['query'])\n",
        "\n",
        "  result_tfidf = rank_tfidf(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "  result_okapi = rank_okapi(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "  result_langModel = rank_langModel(query_tokens, termDict, docs_tokens, verbose=0)\n",
        "\n",
        "  points_tfidf = k_point_interpolated_avg_prec(result_tfidf, relevants)\n",
        "  points_okapi = k_point_interpolated_avg_prec(result_okapi, relevants)\n",
        "  points_langModel = k_point_interpolated_avg_prec(result_langModel, relevants)\n",
        "\n",
        "  points.loc[points['method'] == 'okapi', 'precision'] = points_okapi['precision'].values\n",
        "  points.loc[points['method'] == 'tfidf', 'precision'] = points_tfidf['precision'].values\n",
        "  points.loc[points['method'] == 'langModel', 'precision'] = points_langModel['precision'].values\n",
        "\n",
        "  fig = px.line(points, x=\"recall\", y=\"precision\", color='method')\n",
        "  fig.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "fdX410Wc8-oO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotQuery(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "a-730_jW_Xpq",
        "outputId": "4d39166a-0add-4b72-842c-4c7ca13a5678"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1297a84e-b1fa-4f65-abe2-2e5d3c66cd8b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1297a84e-b1fa-4f65-abe2-2e5d3c66cd8b\")) {                    Plotly.newPlot(                        \"1297a84e-b1fa-4f65-abe2-2e5d3c66cd8b\",                        [{\"hovertemplate\":\"method=tfidf\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"tfidf\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"tfidf\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.25,0.11538461538461539,0.17647058823529413,0.07258064516129033,0.0821917808219178,0.06896551724137931,0.06910569105691057,0.05934718100890208,0.03554868624420402,0.035961272475795295,0.035668789808917196],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"method=okapi\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"okapi\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"okapi\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.5,0.3333333333333333,0.24,0.23076923076923078,0.14814814814814814,0.125,0.10179640718562874,0.08547008547008547,0.04092526690391459,0.034574468085106384,0.035668789808917196],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"method=langModel\\u003cbr\\u003erecall=%{x}\\u003cbr\\u003eprecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"langModel\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"langModel\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.5,0.2,0.24,0.25,0.17142857142857143,0.11570247933884298,0.1069182389937107,0.07782101167315175,0.0387858347386172,0.033766233766233764,0.035668789808917196],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"recall\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"precision\"}},\"legend\":{\"title\":{\"text\":\"method\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1297a84e-b1fa-4f65-abe2-2e5d3c66cd8b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}